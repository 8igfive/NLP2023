{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习自然语言处理第二次作业\n",
    "\n",
    "##### 李明昕 SY2206124"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EM 算法原理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM 算法用于估计既含有观测变量又含有隐变量的概率模型的参数，其原理如下$^{[1]}$：\n",
    "\n",
    "假设观测变量数据为 $Y$ ，隐变量数据为 $Z$ ，他们的联合分布为 $P(Y,Z|\\theta)$ ，条件分布为 $P(Z|Y,\\theta)$ ，其中 $\\theta$ 为模型参数。EM 算法的过程如下：\n",
    "\n",
    "1. 选择参数的初值 $\\theta^{(0)}$ ，开始迭代；\n",
    "2. E 步：记 $\\theta^{(i)}$ 为第 $i$ 次迭代参数 $\\theta$ 的估计值，在第 $i + 1$ 次迭代的 E 步，计算\n",
    "   $$\n",
    "    \\begin{aligned}\n",
    "    Q(\\theta,\\theta^{(i)}) &= E_Z[\\log P(Y,Z|\\theta)|Y,\\theta^{(i)}]\\\\\n",
    "    &= \\sum_Z \\log P(Y,Z|\\theta)P(Z|Y,\\theta^{(i)}).\n",
    "    \\end{aligned}\n",
    "   $$\n",
    "   这里 $P(Z|Y,\\theta^{(i)})$ 是在给定观测数据 $Y$ 和当前的参数估计 $\\theta^{(i)}$ 下隐变量 $Z$ 的条件概率分布；\n",
    "3. M 步：求使 $Q(\\theta,\\theta^{(i)})$ 极大化的 $\\theta$ ，确定第 $i + 1$ 次迭代的参数估计值 $\\theta^{(i + 1)}$\n",
    "   $$\n",
    "    \\theta^{(i + 1)} = \\arg\\max_\\theta Q(\\theta,\\theta^{(i)});\n",
    "   $$ \n",
    "4. 重复 2、3 步，直到收敛。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 身高高斯混合模型参数估计"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 模型定义   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "身高的概率模型假设为一种高斯混合分布，其中观测变量 $y$ 为身高（单位 cm），隐变量 $z$ 为性别（$z=0$ 时表示男生， $z=1$ 时表示女生）。概率模型表示为：\n",
    "\n",
    "+ 表示男生身高的高斯分布：\n",
    "  $$\n",
    "    P(y|z=0,\\theta) = N(y|\\mu_0,\\sigma_0^2)\n",
    "  $$\n",
    "+ 表示女生身高的高斯分布：\n",
    "  $$\n",
    "    P(y|z=1,\\theta) = N(y|\\mu_1,\\sigma_1^2)\n",
    "  $$\n",
    "+ 表示性别的分布：\n",
    "  $$\n",
    "    P(z) = \\begin{cases}\n",
    "    \\pi & z=0\\\\\n",
    "    1-\\pi & z=1\n",
    "    \\end{cases}\n",
    "  $$\n",
    "+ 则表示身高的高斯混合分布为：\n",
    "  $$\n",
    "    P(y) = \\pi N(y|\\mu_0,\\sigma_0^2) + (1-\\pi) N(y|\\mu_1,\\sigma_1^2)\n",
    "  $$\n",
    "  参数为 $\\theta = \\{\\mu_0,\\sigma_0^2,\\mu_1,\\sigma_1^2,\\pi\\}$ 。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 EM 算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设观测变量数据为：$Y=\\{y_1,y_2,\\cdots,y_n\\}$ ，隐变量观测数据为：$Z=\\{z_1,z_2,\\cdots,z_n\\}$，其中 $y_i, z_i$ 独立同分布，则：\n",
    "1. E 步：\n",
    "\n",
    "   $$\n",
    "    \\begin{aligned}\n",
    "      Q(\\theta,\\theta^{(i)}) =& \\sum_Z\\log P(Y,Z|\\theta)P(Z|Y,\\theta^{(i)}) \\\\\n",
    "      =&\\sum_Z\\log \\prod_{j=1}^nP(y_j,z_j|\\theta)P(z_j|y_j,\\theta^{(i)}) \\\\\n",
    "      =&\\sum_Z\\sum_{j=1}^n\\log P(y_j,z_j|\\theta)P(z_j|y_j,\\theta^{(i)}) \\\\\n",
    "      =&2^{n-1}\\sum_{j=1}\\log\\left(P(y_j,z_j=0|\\theta)P(z_j=0|y_i,\\theta^{(i)}) + P(y_j,z_j=1|\\theta)P(z_j=1|y_j,\\theta^{(i)})\\right) \\\\\n",
    "      =&2^{n-1}\\sum_{j=1}\\log\\Big(\\pi N(y_j|\\mu_0,\\sigma_0^2)\\frac{\\pi^{(i)}N(y_j|\\mu_0^{(i)}, \\sigma_0^{(i)})}{\\pi^{(i)}N(y_j|\\mu_0^{(i)}, \\sigma_0^{(i)}) + (1-\\pi^{(i)})N(y_j|\\mu_1^{(i)}, \\sigma_1^{(i)})} \\\\\n",
    "      &+ (1-\\pi)N(y_j|\\mu_1,\\sigma_1^2)\\frac{(1-\\pi^{(i)})N(y_j|\\mu_1^{(i)}, \\sigma_1^{(i)})}{\\pi^{(i)}N(y_j|\\mu_0^{(i)}, \\sigma_0^{(i)}) + (1-\\pi^{(i)})N(y_j|\\mu_1^{(i)}, \\sigma_1^{(i)})}\\Big) \\\\\n",
    "    \\end{aligned}\n",
    "   $$\n",
    "   \n",
    "   记 $\\log$ 内的式子为 $A_j$ 。\n",
    "2. M 步：通过极大似然估计求解参数 $\\theta$ ，得到参数估计值 $\\theta^{(i+1)}$ 。\n",
    "\n",
    "   首先需要计算：$\\gamma_j^{(i)} = P(z_j=0|y_j, \\theta^{(i)}) = \\frac{\\pi^{(i)}N(y_j|\\mu_0^{(i)}, \\sigma_0^{(i)})}{\\pi^{(i)}N(y_j|\\mu_0^{(i)}, \\sigma_0^{(i)}) + (1-\\pi^{(i)})N(y_j|\\mu_1^{(i)}, \\sigma_1^{(i)})}$ 。\n",
    "\n",
    "   然后每个参数的估计值如下：\n",
    "\n",
    "   + $\\pi^{(i+1)} = \\frac{1}{n}\\sum_{j=1}^n\\gamma_j^{(i)}$ ；\n",
    "   + $\\mu_0^{(i+1)} = \\frac{\\sum_{j=1}^n\\gamma_j^{(i)}y_j}{\\sum_{j=1}^n\\gamma_j^{(i)}}$ ；\n",
    "   + $\\mu_1^{(i+1)} = \\frac{\\sum_{j=1}^n(1-\\gamma_j^{(i)})y_j}{\\sum_{j=1}^n(1-\\gamma_j^{(i)})}$ ；\n",
    "   + $(\\sigma_0^{(i+1)})^2 = \\frac{\\sum_{j=1}^n\\gamma_j^{(i)}(y_j-\\mu_0^{(i)})^2}{\\sum_{j=1}^n\\gamma_j^{(i)}}$ ；\n",
    "   + $(\\sigma_1^{(i+1)})^2 = \\frac{\\sum_{j=1}^n(1-\\gamma_j^{(i)})(y_j-\\mu_1^{(i)})^2}{\\sum_{j=1}^n(1-\\gamma_j^{(i)})}$ 。\n",
    "\n",
    "3. 重复 2、3 步，直到参数估计值的变化小于某个阈值。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'src\\height_data.csv'\n",
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 计算 $\\gamma_j$（E 步）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(theta: Dict[str, float], data: pd.DataFrame) -> List[float]:\n",
    "    gammas = []\n",
    "    for i in range(len(data)):\n",
    "        gamma0 = theta['pi'] * norm.pdf(data['height'][i], loc=theta['mu_0'], scale=theta['sigma2_0']**(1/2))\n",
    "        gamma1 = (1 - theta['pi']) * norm.pdf(data['height'][i], loc=theta['mu_1'], scale=theta['sigma2_1']**(1/2))\n",
    "        gammas.append(gamma0 / (gamma0 + gamma1))\n",
    "    return gammas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3 计算新的参数估计值（M 步）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(theta: Dict[str, float], gammas: List[float], data: pd.DataFrame):\n",
    "    new_pi = sum(gammas) / len(gammas)\n",
    "    new_mu_0 = sum(gammas[i] * data['height'][i] for i in range(len(gammas))) / sum(gammas)\n",
    "    new_mu_1 = sum((1 - gammas[i]) * data['height'][i] for i in range(len(gammas))) / (len(gammas) - sum(gammas))\n",
    "    new_sigma2_0 = sum(gammas[i] * (data['height'][i] - theta['mu_0']) ** 2 for i in range(len(gammas))) / sum(gammas)\n",
    "    new_sigma2_1 = sum((1 - gammas[i]) * (data['height'][i] - theta['mu_1']) ** 2 for i in range(len(data))) / (len(data) - sum(gammas))\n",
    "    return {\n",
    "        'pi': new_pi,\n",
    "        'mu_0': new_mu_0,\n",
    "        'mu_1': new_mu_1,\n",
    "        'sigma2_0': new_sigma2_0,\n",
    "        'sigma2_1': new_sigma2_1\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.4 迭代估计参数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(theta_0: Dict[str, float], data: pd.DataFrame, threshold: float = 1e-5):\n",
    "    thetas = [theta_0]\n",
    "    while True:\n",
    "        pre_theta = thetas[-1]\n",
    "        gammas = E_step(pre_theta, data)\n",
    "        new_theta = M_step(pre_theta, gammas, data)\n",
    "        thetas.append(new_theta)\n",
    "        if max(abs(new_theta[key] - pre_theta[key]) for key in new_theta) < threshold:\n",
    "            break\n",
    "    return thetas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从生成数据的代码中可以看出，各个参数的真实值为：\n",
    "+ $\\pi^{\\mathrm{ture}} = 0.75$\n",
    "+ $\\mu_O^{\\mathrm{ture}} = 176$\n",
    "+ $\\mu_1^{\\mathrm{ture}} = 164$\n",
    "+ $(\\sigma_0^{\\mathrm{ture}})^2 = 25$\n",
    "+ $(\\sigma_1^{\\mathrm{ture}})^2 = 9$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true = {\n",
    "    'pi': 0.75,\n",
    "    'mu_0': 176,\n",
    "    'mu_1': 165,\n",
    "    'sigma2_0': 25,\n",
    "    'sigma2_1': 9\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据先验设定初始参数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num: 134\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5517\n",
      "sigma2_1: 8.6329\n"
     ]
    }
   ],
   "source": [
    "# 根据官方数据，我国的男女比例以及男女身高的均值和标准差为\n",
    "theta_0 = {\n",
    "    'pi': 0.5169,\n",
    "    'mu_0': 169.7,\n",
    "    'mu_1': 158.,\n",
    "    'sigma2_0': 10,\n",
    "    'sigma2_1': 10\n",
    "}\n",
    "\n",
    "thetas = EM(theta_0, data, threshold=1e-5)\n",
    "print(f'iteration num: {len(thetas)}')\n",
    "for p, v in thetas[-1].items():\n",
    "    print(f'{p}: {v:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 平均相对误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average relative error: 0.02134774314920935\n"
     ]
    }
   ],
   "source": [
    "# 平均相对误差为\n",
    "print(f'average relative error: {sum(abs(thetas[-1][key] - theta_true[key]) / theta_true[key] for key in thetas[-1]) / len(thetas[-1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以使用我国官方的数据进行参数初始化，经过 EM 算法后的结果为：\n",
    "\n",
    "| 参数 | 估计值 | 真实值 |\n",
    "| --- | --- | --- |\n",
    "| $\\pi$ | 0.75 | 0.75 |\n",
    "| $\\mu_0$ | 176.26 | 176.00 |\n",
    "| $\\mu_1$ | 164.93 | 164.00 |\n",
    "| $(\\sigma_0)^2$ | 23.55 | 25.00 |\n",
    "| $(\\sigma_1)^2$ | 8.63 | 9.00 |\n",
    "\n",
    "平均相对误差为：0.02135"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 实验结果可视化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![experiment_1](resources/experiment_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在给定范围内初始化参数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 EM 算法对初始值敏感，所以在给定范围内初始化多组参数，然后进行 EM 算法，以此来验证 EM 算法的稳定性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init theta: {'pi': 0.1, 'mu_0': 170.0, 'mu_1': 155.0, 'sigma2_0': 5.0, 'sigma2_1': 5.0}\n",
      "iteration num: 137\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5517\n",
      "sigma2_1: 8.6329\n",
      "average relative error: 0.02134772532970382\n",
      "--------------------\n",
      "init theta: {'pi': 0.18888888888888888, 'mu_0': 171.11111111111111, 'mu_1': 156.11111111111111, 'sigma2_0': 6.111111111111111, 'sigma2_1': 6.111111111111111}\n",
      "iteration num: 132\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5517\n",
      "sigma2_1: 8.6329\n",
      "average relative error: 0.02134772411528298\n",
      "--------------------\n",
      "init theta: {'pi': 0.2777777777777778, 'mu_0': 172.22222222222223, 'mu_1': 157.22222222222223, 'sigma2_0': 7.222222222222222, 'sigma2_1': 7.222222222222222}\n",
      "iteration num: 125\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5517\n",
      "sigma2_1: 8.6329\n",
      "average relative error: 0.021347748634670115\n",
      "--------------------\n",
      "init theta: {'pi': 0.3666666666666667, 'mu_0': 173.33333333333334, 'mu_1': 158.33333333333334, 'sigma2_0': 8.333333333333334, 'sigma2_1': 8.333333333333334}\n",
      "iteration num: 114\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5517\n",
      "sigma2_1: 8.6329\n",
      "average relative error: 0.021347729420471907\n",
      "--------------------\n",
      "init theta: {'pi': 0.4555555555555556, 'mu_0': 174.44444444444446, 'mu_1': 159.44444444444446, 'sigma2_0': 9.444444444444445, 'sigma2_1': 9.444444444444445}\n",
      "iteration num: 105\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.02134692674047107\n",
      "--------------------\n",
      "init theta: {'pi': 0.5444444444444445, 'mu_0': 175.55555555555554, 'mu_1': 160.55555555555554, 'sigma2_0': 10.555555555555555, 'sigma2_1': 10.555555555555555}\n",
      "iteration num: 120\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.021346931435337613\n",
      "--------------------\n",
      "init theta: {'pi': 0.6333333333333333, 'mu_0': 176.66666666666666, 'mu_1': 161.66666666666666, 'sigma2_0': 11.666666666666668, 'sigma2_1': 11.666666666666668}\n",
      "iteration num: 126\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.021346943005824535\n",
      "--------------------\n",
      "init theta: {'pi': 0.7222222222222222, 'mu_0': 177.77777777777777, 'mu_1': 162.77777777777777, 'sigma2_0': 12.777777777777779, 'sigma2_1': 12.777777777777779}\n",
      "iteration num: 129\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.02134692929448389\n",
      "--------------------\n",
      "init theta: {'pi': 0.8111111111111111, 'mu_0': 178.88888888888889, 'mu_1': 163.88888888888889, 'sigma2_0': 13.88888888888889, 'sigma2_1': 13.88888888888889}\n",
      "iteration num: 131\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.021346932163651654\n",
      "--------------------\n",
      "init theta: {'pi': 0.9, 'mu_0': 180.0, 'mu_1': 165.0, 'sigma2_0': 15.0, 'sigma2_1': 15.0}\n",
      "iteration num: 131\n",
      "pi: 0.7500\n",
      "mu_0: 176.2608\n",
      "mu_1: 163.9262\n",
      "sigma2_0: 23.5515\n",
      "sigma2_1: 8.6330\n",
      "average relative error: 0.021346942754384195\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 不同的参数初始化\n",
    "pis = np.linspace(0.1, 0.9, 10)\n",
    "mus_0 = np.linspace(170., 180., 10)\n",
    "mus_1 = np.linspace(155., 165., 10)\n",
    "sigma2s_0 = np.linspace(5., 15., 10)\n",
    "sigma2s_1 = np.linspace(5., 15., 10)\n",
    "init_thetas = [{'pi': pi, 'mu_0': mu_0, 'mu_1': mu_1, 'sigma2_0': sigma2_0, 'sigma2_1': sigma2_1} \n",
    "                for pi, mu_0, mu_1, sigma2_0, sigma2_1 in zip(pis, mus_0, mus_1, sigma2s_0, sigma2s_1)]\n",
    "\n",
    "# 从不同的初始值开始 EM 算法，并输出结果\n",
    "for theta_0 in init_thetas:\n",
    "    thetas = EM(theta_0, data, threshold=1e-5)\n",
    "    theta = thetas[-1]\n",
    "    print(f'init theta: {theta_0}')\n",
    "    print(f'iteration num: {len(thetas)}')\n",
    "    for p, v in theta.items():\n",
    "        print(f'{p}: {v:.4f}')\n",
    "    print(f'average relative error: {sum(abs(theta[key] - theta_true[key]) / theta_true[key] for key in theta) / len(theta)}')\n",
    "    print('-' * 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到模型在不同参数初始化下也能收敛到相近的结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献\n",
    "\n",
    "[1] 李航.统计学习方法.北京:清华大学出版社,2012:175-187."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
